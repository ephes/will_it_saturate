{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-brooks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# hide\\n\\nfrom pprint import pprint\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# hide\\n\\nfrom pprint import pprint\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-ebony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# default_exp core\";\n",
       "                var nbb_formatted_code = \"# default_exp core\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-thermal",
   "metadata": {},
   "source": [
    "# module Core\n",
    "\n",
    "> Core benchmark logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-traveler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# export\\n\\nimport os\\nimport math\\nimport json\\nimport hashlib\\n\\nimport pandas as pd\\n\\nfrom pathlib import Path\\nfrom typing import Optional, Callable, Any\\n\\nfrom pydantic import BaseModel\";\n",
       "                var nbb_formatted_code = \"# export\\n\\nimport os\\nimport math\\nimport json\\nimport hashlib\\n\\nimport pandas as pd\\n\\nfrom pathlib import Path\\nfrom typing import Optional, Callable, Any\\n\\nfrom pydantic import BaseModel\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, Any\n",
    "\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-least",
   "metadata": {},
   "source": [
    "# Benchmark Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-rogers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\nclass BenchmarkServer(BaseModel):\\n    name: str = \\\"base_server\\\"\\n\\n    def start(self):\\n        # do nothing\\n        pass\\n\\n    def stop(self):\\n        # do nothing\\n        pass\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\nclass BenchmarkServer(BaseModel):\\n    name: str = \\\"base_server\\\"\\n\\n    def start(self):\\n        # do nothing\\n        pass\\n\\n    def stop(self):\\n        # do nothing\\n        pass\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class BenchmarkServer(BaseModel):\n",
    "    name: str = \"base_server\"\n",
    "\n",
    "    def start(self):\n",
    "        # do nothing\n",
    "        pass\n",
    "\n",
    "    def stop(self):\n",
    "        # do nothing\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-milan",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-association",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"name = \\\"Nginx Docker\\\"\\nserver = BenchmarkServer(name=name)\";\n",
       "                var nbb_formatted_code = \"name = \\\"Nginx Docker\\\"\\nserver = BenchmarkServer(name=name)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"Nginx Docker\"\n",
    "server = BenchmarkServer(name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-theme",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"assert server.name == name\\nassert server.start() is None\\nassert server.stop() is None\";\n",
       "                var nbb_formatted_code = \"assert server.name == name\\nassert server.start() is None\\nassert server.stop() is None\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert server.name == name\n",
    "assert server.start() is None\n",
    "assert server.stop() is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-individual",
   "metadata": {},
   "source": [
    "# Checksum Mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-venture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\nclass CheckSumMixin:\\n    def calculate_checksum(self, content):\\n        return hashlib.md5(content).hexdigest()\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\nclass CheckSumMixin:\\n    def calculate_checksum(self, content):\\n        return hashlib.md5(content).hexdigest()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class CheckSumMixin:\n",
    "    def calculate_checksum(self, content):\n",
    "        return hashlib.md5(content).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-relations",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class FooBar(CheckSumMixin):\\n    def some_method_returning_checksum(self, content):\\n        return self.calculate_checksum(content)\\n\\n\\nfoobar = FooBar()\";\n",
       "                var nbb_formatted_code = \"class FooBar(CheckSumMixin):\\n    def some_method_returning_checksum(self, content):\\n        return self.calculate_checksum(content)\\n\\n\\nfoobar = FooBar()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FooBar(CheckSumMixin):\n",
    "    def some_method_returning_checksum(self, content):\n",
    "        return self.calculate_checksum(content)\n",
    "\n",
    "\n",
    "foobar = FooBar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-finder",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"test_content = b\\\"foobar\\\"\\nassert (\\n    foobar.some_method_returning_checksum(test_content)\\n    == hashlib.md5(test_content).hexdigest()\\n)\";\n",
       "                var nbb_formatted_code = \"test_content = b\\\"foobar\\\"\\nassert (\\n    foobar.some_method_returning_checksum(test_content)\\n    == hashlib.md5(test_content).hexdigest()\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_content = b\"foobar\"\n",
    "assert (\n",
    "    foobar.some_method_returning_checksum(test_content)\n",
    "    == hashlib.md5(test_content).hexdigest()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-survey",
   "metadata": {},
   "source": [
    "# Benchmark Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-powder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\nclass BenchmarkClient(CheckSumMixin, BaseModel):\\n    name: str = \\\"base_client\\\"\\n\\n    def verify_checksums(self, benchmark_files, responses):\\n        checksum_lookup = {}\\n        for response in responses:\\n            url = str(response.url)\\n            checksum_lookup[url] = self.calculate_checksum(response.content)\\n\\n        for bf in benchmark_files:\\n            looked_up_checksum = checksum_lookup.get(bf.url, None)\\n            if bf.checksum != looked_up_checksum:\\n                print(bf.checksum, bf.url)\\n            assert bf.checksum == checksum_lookup.get(bf.url, None)\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\nclass BenchmarkClient(CheckSumMixin, BaseModel):\\n    name: str = \\\"base_client\\\"\\n\\n    def verify_checksums(self, benchmark_files, responses):\\n        checksum_lookup = {}\\n        for response in responses:\\n            url = str(response.url)\\n            checksum_lookup[url] = self.calculate_checksum(response.content)\\n\\n        for bf in benchmark_files:\\n            looked_up_checksum = checksum_lookup.get(bf.url, None)\\n            if bf.checksum != looked_up_checksum:\\n                print(bf.checksum, bf.url)\\n            assert bf.checksum == checksum_lookup.get(bf.url, None)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class BenchmarkClient(CheckSumMixin, BaseModel):\n",
    "    name: str = \"base_client\"\n",
    "\n",
    "    def verify_checksums(self, benchmark_files, responses):\n",
    "        checksum_lookup = {}\n",
    "        for response in responses:\n",
    "            url = str(response.url)\n",
    "            checksum_lookup[url] = self.calculate_checksum(response.content)\n",
    "\n",
    "        for bf in benchmark_files:\n",
    "            looked_up_checksum = checksum_lookup.get(bf.url, None)\n",
    "            if bf.checksum != looked_up_checksum:\n",
    "                print(bf.checksum, bf.url)\n",
    "            assert bf.checksum == checksum_lookup.get(bf.url, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-child",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-offense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"name = \\\"Httpx\\\"\\nclient = BenchmarkClient(name=name)\";\n",
       "                var nbb_formatted_code = \"name = \\\"Httpx\\\"\\nclient = BenchmarkClient(name=name)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"Httpx\"\n",
    "client = BenchmarkClient(name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-halifax",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"assert client.name == name\";\n",
       "                var nbb_formatted_code = \"assert client.name == name\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert client.name == name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-nirvana",
   "metadata": {},
   "source": [
    "# Benchmark Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-introduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\nclass FilesystemCreator(CheckSumMixin, BaseModel):\\n    def checksum_for_path(self, path):\\n        with path.open(\\\"rb\\\") as f:\\n            checksum = self.calculate_checksum(f.read())\\n        return checksum\\n\\n    def __call__(self, path, size):\\n        path.parent.mkdir(parents=True, exist_ok=True)\\n        if not path.exists():\\n            with path.open(\\\"wb\\\") as f:\\n                f.write(os.urandom(size))\\n        return self.checksum_for_path(path)\\n\\n\\nclass BenchmarkFile(BaseModel):\\n    number: int\\n    base_path: str\\n    size: int\\n    data_root: str = \\\"data\\\"\\n    hostname: str = \\\"localhost\\\"\\n    port: int = 8000\\n    checksum: Optional[str] = None\\n    creator: Callable = FilesystemCreator()\\n\\n    @property\\n    def filesystem_path(self):\\n        return Path(self.data_root) / self.base_path / str(self.number)\\n\\n    def get_or_create(self):\\n        self.checksum = self.creator(self.filesystem_path, self.size)\\n\\n    @property\\n    def path(self):\\n        return f\\\"{self.data_root}/{self.base_path}/{self.number}\\\"\\n\\n    @property\\n    def host(self):\\n        return f\\\"http://{self.hostname}:{self.port}\\\"\\n\\n    @property\\n    def url(self):\\n        return f\\\"{self.host}/{self.path}\\\"\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\nclass FilesystemCreator(CheckSumMixin, BaseModel):\\n    def checksum_for_path(self, path):\\n        with path.open(\\\"rb\\\") as f:\\n            checksum = self.calculate_checksum(f.read())\\n        return checksum\\n\\n    def __call__(self, path, size):\\n        path.parent.mkdir(parents=True, exist_ok=True)\\n        if not path.exists():\\n            with path.open(\\\"wb\\\") as f:\\n                f.write(os.urandom(size))\\n        return self.checksum_for_path(path)\\n\\n\\nclass BenchmarkFile(BaseModel):\\n    number: int\\n    base_path: str\\n    size: int\\n    data_root: str = \\\"data\\\"\\n    hostname: str = \\\"localhost\\\"\\n    port: int = 8000\\n    checksum: Optional[str] = None\\n    creator: Callable = FilesystemCreator()\\n\\n    @property\\n    def filesystem_path(self):\\n        return Path(self.data_root) / self.base_path / str(self.number)\\n\\n    def get_or_create(self):\\n        self.checksum = self.creator(self.filesystem_path, self.size)\\n\\n    @property\\n    def path(self):\\n        return f\\\"{self.data_root}/{self.base_path}/{self.number}\\\"\\n\\n    @property\\n    def host(self):\\n        return f\\\"http://{self.hostname}:{self.port}\\\"\\n\\n    @property\\n    def url(self):\\n        return f\\\"{self.host}/{self.path}\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class FilesystemCreator(CheckSumMixin, BaseModel):\n",
    "    def checksum_for_path(self, path):\n",
    "        with path.open(\"rb\") as f:\n",
    "            checksum = self.calculate_checksum(f.read())\n",
    "        return checksum\n",
    "\n",
    "    def __call__(self, path, size):\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not path.exists():\n",
    "            with path.open(\"wb\") as f:\n",
    "                f.write(os.urandom(size))\n",
    "        return self.checksum_for_path(path)\n",
    "\n",
    "\n",
    "class BenchmarkFile(BaseModel):\n",
    "    number: int\n",
    "    base_path: str\n",
    "    size: int\n",
    "    data_root: str = \"data\"\n",
    "    hostname: str = \"localhost\"\n",
    "    port: int = 8000\n",
    "    checksum: Optional[str] = None\n",
    "    creator: Callable = FilesystemCreator()\n",
    "\n",
    "    @property\n",
    "    def filesystem_path(self):\n",
    "        return Path(self.data_root) / self.base_path / str(self.number)\n",
    "\n",
    "    def get_or_create(self):\n",
    "        self.checksum = self.creator(self.filesystem_path, self.size)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return f\"{self.data_root}/{self.base_path}/{self.number}\"\n",
    "\n",
    "    @property\n",
    "    def host(self):\n",
    "        return f\"http://{self.hostname}:{self.port}\"\n",
    "\n",
    "    @property\n",
    "    def url(self):\n",
    "        return f\"{self.host}/{self.path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-celtic",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:8000/data/3000000_2_12500000/0'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"base_path = \\\"3000000_2_12500000\\\"\\nbenchmark_file = BenchmarkFile(number=0, size=10 ** 6 * 3, base_path=base_path)\\nbenchmark_file.url\";\n",
       "                var nbb_formatted_code = \"base_path = \\\"3000000_2_12500000\\\"\\nbenchmark_file = BenchmarkFile(number=0, size=10 ** 6 * 3, base_path=base_path)\\nbenchmark_file.url\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_path = \"3000000_2_12500000\"\n",
    "benchmark_file = BenchmarkFile(number=0, size=10 ** 6 * 3, base_path=base_path)\n",
    "benchmark_file.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-blowing",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-function",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"assert \\\"localhost\\\" in benchmark_file.url\\nassert base_path in benchmark_file.url\\nassert \\\"base_path\\\" in benchmark_file.json()\";\n",
       "                var nbb_formatted_code = \"assert \\\"localhost\\\" in benchmark_file.url\\nassert base_path in benchmark_file.url\\nassert \\\"base_path\\\" in benchmark_file.json()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert \"localhost\" in benchmark_file.url\n",
    "assert base_path in benchmark_file.url\n",
    "assert \"base_path\" in benchmark_file.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-investor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"file_size = 10 ** 6 * 3\\n\\n\\nclass TestCreator:\\n    def __call__(self, path, size):\\n        assert size == file_size\\n        return \\\"test_md5sum\\\"\\n\\n\\nbenchmark_file = BenchmarkFile(\\n    number=0, size=file_size, base_path=base_path, creator=TestCreator()\\n)\\nbenchmark_file.get_or_create()\";\n",
       "                var nbb_formatted_code = \"file_size = 10 ** 6 * 3\\n\\n\\nclass TestCreator:\\n    def __call__(self, path, size):\\n        assert size == file_size\\n        return \\\"test_md5sum\\\"\\n\\n\\nbenchmark_file = BenchmarkFile(\\n    number=0, size=file_size, base_path=base_path, creator=TestCreator()\\n)\\nbenchmark_file.get_or_create()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_size = 10 ** 6 * 3\n",
    "\n",
    "\n",
    "class TestCreator:\n",
    "    def __call__(self, path, size):\n",
    "        assert size == file_size\n",
    "        return \"test_md5sum\"\n",
    "\n",
    "\n",
    "benchmark_file = BenchmarkFile(\n",
    "    number=0, size=file_size, base_path=base_path, creator=TestCreator()\n",
    ")\n",
    "benchmark_file.get_or_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-shift",
   "metadata": {},
   "source": [
    "# Benchmark Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\nclass BenchmarkRow(BaseModel):\\n    file_size: int  # size of a single file\\n    duration: int = 30  # in seconds\\n    bandwidth: int = int(10 ** 9 / 8)  # in bytes per second\\n    files: list[BenchmarkFile] = []\\n    file_creator: Callable = FilesystemCreator()\\n    elapsed: Optional[float] = None\\n    data_root: str = \\\"data\\\"\\n\\n    def __str__(self):\\n        return f\\\"size: {self.file_size} duration: {self.duration} bandwidth: {self.bandwidth}\\\"\\n\\n    @property\\n    def base_path(self):\\n        return f\\\"{self.file_size}_{self.duration}_{self.bandwidth}\\\"\\n\\n    @property\\n    def complete_size(self):\\n        return self.duration * self.bandwidth\\n\\n    @property\\n    def number_of_files(self):\\n        return math.ceil(self.complete_size / self.file_size)\\n\\n    @property\\n    def number_of_connections(self):\\n        return math.ceil(self.bandwidth / self.file_size)\\n\\n    def get_bytes_per_second(self, elapsed):\\n        return self.complete_size / elapsed\\n\\n    @property\\n    def bytes_per_second(self):\\n        return self.complete_size / self.elapsed\\n\\n    def create_files(self):\\n        if len(self.files) > 0:\\n            return\\n        for num in range(self.number_of_files):\\n            benchmark_file = BenchmarkFile(\\n                number=num,\\n                base_path=self.base_path,\\n                size=self.file_size,\\n                creator=self.file_creator,\\n                data_root=self.data_root,\\n            )\\n            benchmark_file.get_or_create()\\n            self.files.append(benchmark_file)\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\nclass BenchmarkRow(BaseModel):\\n    file_size: int  # size of a single file\\n    duration: int = 30  # in seconds\\n    bandwidth: int = int(10 ** 9 / 8)  # in bytes per second\\n    files: list[BenchmarkFile] = []\\n    file_creator: Callable = FilesystemCreator()\\n    elapsed: Optional[float] = None\\n    data_root: str = \\\"data\\\"\\n\\n    def __str__(self):\\n        return f\\\"size: {self.file_size} duration: {self.duration} bandwidth: {self.bandwidth}\\\"\\n\\n    @property\\n    def base_path(self):\\n        return f\\\"{self.file_size}_{self.duration}_{self.bandwidth}\\\"\\n\\n    @property\\n    def complete_size(self):\\n        return self.duration * self.bandwidth\\n\\n    @property\\n    def number_of_files(self):\\n        return math.ceil(self.complete_size / self.file_size)\\n\\n    @property\\n    def number_of_connections(self):\\n        return math.ceil(self.bandwidth / self.file_size)\\n\\n    def get_bytes_per_second(self, elapsed):\\n        return self.complete_size / elapsed\\n\\n    @property\\n    def bytes_per_second(self):\\n        return self.complete_size / self.elapsed\\n\\n    def create_files(self):\\n        if len(self.files) > 0:\\n            return\\n        for num in range(self.number_of_files):\\n            benchmark_file = BenchmarkFile(\\n                number=num,\\n                base_path=self.base_path,\\n                size=self.file_size,\\n                creator=self.file_creator,\\n                data_root=self.data_root,\\n            )\\n            benchmark_file.get_or_create()\\n            self.files.append(benchmark_file)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class BenchmarkRow(BaseModel):\n",
    "    file_size: int  # size of a single file\n",
    "    duration: int = 30  # in seconds\n",
    "    bandwidth: int = int(10 ** 9 / 8)  # in bytes per second\n",
    "    files: list[BenchmarkFile] = []\n",
    "    file_creator: Callable = FilesystemCreator()\n",
    "    elapsed: Optional[float] = None\n",
    "    data_root: str = \"data\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"size: {self.file_size} duration: {self.duration} bandwidth: {self.bandwidth}\"\n",
    "\n",
    "    @property\n",
    "    def base_path(self):\n",
    "        return f\"{self.file_size}_{self.duration}_{self.bandwidth}\"\n",
    "\n",
    "    @property\n",
    "    def complete_size(self):\n",
    "        return self.duration * self.bandwidth\n",
    "\n",
    "    @property\n",
    "    def number_of_files(self):\n",
    "        return math.ceil(self.complete_size / self.file_size)\n",
    "\n",
    "    @property\n",
    "    def number_of_connections(self):\n",
    "        return math.ceil(self.bandwidth / self.file_size)\n",
    "\n",
    "    def get_bytes_per_second(self, elapsed):\n",
    "        return self.complete_size / elapsed\n",
    "\n",
    "    @property\n",
    "    def bytes_per_second(self):\n",
    "        return self.complete_size / self.elapsed\n",
    "\n",
    "    def create_files(self):\n",
    "        if len(self.files) > 0:\n",
    "            return\n",
    "        for num in range(self.number_of_files):\n",
    "            benchmark_file = BenchmarkFile(\n",
    "                number=num,\n",
    "                base_path=self.base_path,\n",
    "                size=self.file_size,\n",
    "                creator=self.file_creator,\n",
    "                data_root=self.data_root,\n",
    "            )\n",
    "            benchmark_file.get_or_create()\n",
    "            self.files.append(benchmark_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-official",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# hide\\n\\n\\nclass DummyCreator(BaseModel):\\n    def __call__(self, path, size):\\n        return \\\"dummy\\\"\";\n",
       "                var nbb_formatted_code = \"# hide\\n\\n\\nclass DummyCreator(BaseModel):\\n    def __call__(self, path, size):\\n        return \\\"dummy\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "\n",
    "class DummyCreator(BaseModel):\n",
    "    def __call__(self, path, size):\n",
    "        return \"dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-contrary",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# dont_test\\n\\nbyte = 8\\nhundred_mbit = 10 ** 8\\nbandwidth = hundred_mbit / byte\\nduration = 2  # seconds\\nfile_size = 10 ** 6 * 3  # 100MB\\n\\nbenchmark_row = BenchmarkRow(\\n    file_size=file_size,\\n    duration=duration,\\n    bandwidth=bandwidth,\\n    file_creator=DummyCreator(),\\n)\\nbenchmark_row.create_files()\\nprint(len(benchmark_row.files))\";\n",
       "                var nbb_formatted_code = \"# dont_test\\n\\nbyte = 8\\nhundred_mbit = 10 ** 8\\nbandwidth = hundred_mbit / byte\\nduration = 2  # seconds\\nfile_size = 10 ** 6 * 3  # 100MB\\n\\nbenchmark_row = BenchmarkRow(\\n    file_size=file_size,\\n    duration=duration,\\n    bandwidth=bandwidth,\\n    file_creator=DummyCreator(),\\n)\\nbenchmark_row.create_files()\\nprint(len(benchmark_row.files))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dont_test\n",
    "\n",
    "byte = 8\n",
    "hundred_mbit = 10 ** 8\n",
    "bandwidth = hundred_mbit / byte\n",
    "duration = 2  # seconds\n",
    "file_size = 10 ** 6 * 3  # 100MB\n",
    "\n",
    "benchmark_row = BenchmarkRow(\n",
    "    file_size=file_size,\n",
    "    duration=duration,\n",
    "    bandwidth=bandwidth,\n",
    "    file_creator=DummyCreator(),\n",
    ")\n",
    "benchmark_row.create_files()\n",
    "print(len(benchmark_row.files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-blind",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-proposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"byte = 8\\ngigabit = 10 ** 9\\n\\ntest_params = {\\n    \\\"file_size\\\": 10 ** 6 * 10,  # 10MB\\n    \\\"duration\\\": 30,\\n    \\\"bandwidth\\\": gigabit / byte,\\n    \\\"file_creator\\\": DummyCreator(),\\n}\\n\\ntest_benchmark_row = BenchmarkRow(**test_params)\";\n",
       "                var nbb_formatted_code = \"byte = 8\\ngigabit = 10 ** 9\\n\\ntest_params = {\\n    \\\"file_size\\\": 10 ** 6 * 10,  # 10MB\\n    \\\"duration\\\": 30,\\n    \\\"bandwidth\\\": gigabit / byte,\\n    \\\"file_creator\\\": DummyCreator(),\\n}\\n\\ntest_benchmark_row = BenchmarkRow(**test_params)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "byte = 8\n",
    "gigabit = 10 ** 9\n",
    "\n",
    "test_params = {\n",
    "    \"file_size\": 10 ** 6 * 10,  # 10MB\n",
    "    \"duration\": 30,\n",
    "    \"bandwidth\": gigabit / byte,\n",
    "    \"file_creator\": DummyCreator(),\n",
    "}\n",
    "\n",
    "test_benchmark_row = BenchmarkRow(**test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"assert test_benchmark_row.bandwidth == 125000000\\nassert test_benchmark_row.number_of_files == 375\\nassert test_benchmark_row.get_bytes_per_second(30.0) == test_benchmark_row.bandwidth\\nassert test_benchmark_row.number_of_connections == 13\\nassert \\\"file_size\\\" in test_benchmark_row.json()\";\n",
       "                var nbb_formatted_code = \"assert test_benchmark_row.bandwidth == 125000000\\nassert test_benchmark_row.number_of_files == 375\\nassert test_benchmark_row.get_bytes_per_second(30.0) == test_benchmark_row.bandwidth\\nassert test_benchmark_row.number_of_connections == 13\\nassert \\\"file_size\\\" in test_benchmark_row.json()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert test_benchmark_row.bandwidth == 125000000\n",
    "assert test_benchmark_row.number_of_files == 375\n",
    "assert test_benchmark_row.get_bytes_per_second(30.0) == test_benchmark_row.bandwidth\n",
    "assert test_benchmark_row.number_of_connections == 13\n",
    "assert \"file_size\" in test_benchmark_row.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"test_benchmark_row.create_files()\\nassert len(test_benchmark_row.files) == test_benchmark_row.number_of_files\\n\\n# assert we don't generate files twice\\ntest_benchmark_row.create_files()\\nassert len(test_benchmark_row.files) == test_benchmark_row.number_of_files\";\n",
       "                var nbb_formatted_code = \"test_benchmark_row.create_files()\\nassert len(test_benchmark_row.files) == test_benchmark_row.number_of_files\\n\\n# assert we don't generate files twice\\ntest_benchmark_row.create_files()\\nassert len(test_benchmark_row.files) == test_benchmark_row.number_of_files\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_benchmark_row.create_files()\n",
    "assert len(test_benchmark_row.files) == test_benchmark_row.number_of_files\n",
    "\n",
    "# assert we don't generate files twice\n",
    "test_benchmark_row.create_files()\n",
    "assert len(test_benchmark_row.files) == test_benchmark_row.number_of_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-compromise",
   "metadata": {},
   "source": [
    "# Benchmark Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\ndef convert_size(size_bytes):\\n    if size_bytes == 0:\\n        return \\\"0B\\\"\\n    size_name = (\\\"B\\\", \\\"KB\\\", \\\"MB\\\", \\\"GB\\\", \\\"TB\\\", \\\"PB\\\", \\\"EB\\\", \\\"ZB\\\", \\\"YB\\\")\\n    i = int(math.floor(math.log(size_bytes, 1024)))\\n    p = math.pow(1024, i)\\n    s = round(size_bytes / p, 2)\\n    return s, size_name[i]\\n\\n\\nclass BenchmarkResult(BaseModel):\\n    server: str\\n    client: str\\n    file_size: int\\n    elapsed: Optional[float] = None\\n    complete_size: int\\n\\n    def __hash__(self):\\n        return hash(self.json(exclude={\\\"elapsed\\\"}))\\n\\n    def __eq__(self, other):\\n        self_dict, other_dict = self.dict(exclude={\\\"elapsed\\\"}), other.dict(\\n            exclude={\\\"elapsed\\\"}\\n        )\\n        return self_dict == other_dict\\n\\n    @classmethod\\n    def build_empty_result(cls, row, server, client):\\n        return cls(\\n            server=server.name,\\n            client=client.name,\\n            file_size=row.file_size,\\n            complete_size=row.complete_size,\\n        )\\n\\n    def make_readable(self, size_in_bytes):\\n        size, unit = convert_size(size_in_bytes)\\n        return f\\\"{size}{unit}\\\"\\n\\n    @property\\n    def readable_file_size(self):\\n        return self.make_readable(self.file_size)\\n\\n    @property\\n    def bytes_per_second(self):\\n        return self.complete_size / self.elapsed\\n\\n    @property\\n    def readable_bytes_per_second(self):\\n        return self.make_readable(self.bytes_per_second)\\n\\n    def dict_with_properties(self):\\n        return {\\n            **super().dict(),\\n            \\\"file_size_h\\\": self.readable_file_size,\\n            \\\"bytes_per_second\\\": self.bytes_per_second,\\n            \\\"bytes_per_second_h\\\": self.readable_bytes_per_second,\\n        }\\n\\n\\n# This does not work yet\\n#     def dict(self):\\n#         _dict = super().dict()\\n#         return {\\n#             **super().dict(),\\n#             \\\"file_size_h\\\": self.readable_file_size,\\n#             \\\"bytes_per_second\\\": self.bytes_per_second,\\n#             \\\"bytes_per_second_h\\\": self.readable_bytes_per_second,\\n#         }\\n\\n#     def json(self):\\n#         return json.dumps(self.dict())\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\ndef convert_size(size_bytes):\\n    if size_bytes == 0:\\n        return \\\"0B\\\"\\n    size_name = (\\\"B\\\", \\\"KB\\\", \\\"MB\\\", \\\"GB\\\", \\\"TB\\\", \\\"PB\\\", \\\"EB\\\", \\\"ZB\\\", \\\"YB\\\")\\n    i = int(math.floor(math.log(size_bytes, 1024)))\\n    p = math.pow(1024, i)\\n    s = round(size_bytes / p, 2)\\n    return s, size_name[i]\\n\\n\\nclass BenchmarkResult(BaseModel):\\n    server: str\\n    client: str\\n    file_size: int\\n    elapsed: Optional[float] = None\\n    complete_size: int\\n\\n    def __hash__(self):\\n        return hash(self.json(exclude={\\\"elapsed\\\"}))\\n\\n    def __eq__(self, other):\\n        self_dict, other_dict = self.dict(exclude={\\\"elapsed\\\"}), other.dict(\\n            exclude={\\\"elapsed\\\"}\\n        )\\n        return self_dict == other_dict\\n\\n    @classmethod\\n    def build_empty_result(cls, row, server, client):\\n        return cls(\\n            server=server.name,\\n            client=client.name,\\n            file_size=row.file_size,\\n            complete_size=row.complete_size,\\n        )\\n\\n    def make_readable(self, size_in_bytes):\\n        size, unit = convert_size(size_in_bytes)\\n        return f\\\"{size}{unit}\\\"\\n\\n    @property\\n    def readable_file_size(self):\\n        return self.make_readable(self.file_size)\\n\\n    @property\\n    def bytes_per_second(self):\\n        return self.complete_size / self.elapsed\\n\\n    @property\\n    def readable_bytes_per_second(self):\\n        return self.make_readable(self.bytes_per_second)\\n\\n    def dict_with_properties(self):\\n        return {\\n            **super().dict(),\\n            \\\"file_size_h\\\": self.readable_file_size,\\n            \\\"bytes_per_second\\\": self.bytes_per_second,\\n            \\\"bytes_per_second_h\\\": self.readable_bytes_per_second,\\n        }\\n\\n\\n# This does not work yet\\n#     def dict(self):\\n#         _dict = super().dict()\\n#         return {\\n#             **super().dict(),\\n#             \\\"file_size_h\\\": self.readable_file_size,\\n#             \\\"bytes_per_second\\\": self.bytes_per_second,\\n#             \\\"bytes_per_second_h\\\": self.readable_bytes_per_second,\\n#         }\\n\\n#     def json(self):\\n#         return json.dumps(self.dict())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return s, size_name[i]\n",
    "\n",
    "\n",
    "class BenchmarkResult(BaseModel):\n",
    "    server: str\n",
    "    client: str\n",
    "    file_size: int\n",
    "    elapsed: Optional[float] = None\n",
    "    complete_size: int\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.json(exclude={\"elapsed\"}))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        self_dict, other_dict = self.dict(exclude={\"elapsed\"}), other.dict(\n",
    "            exclude={\"elapsed\"}\n",
    "        )\n",
    "        return self_dict == other_dict\n",
    "\n",
    "    @classmethod\n",
    "    def build_empty_result(cls, row, server, client):\n",
    "        return cls(\n",
    "            server=server.name,\n",
    "            client=client.name,\n",
    "            file_size=row.file_size,\n",
    "            complete_size=row.complete_size,\n",
    "        )\n",
    "\n",
    "    def make_readable(self, size_in_bytes):\n",
    "        size, unit = convert_size(size_in_bytes)\n",
    "        return f\"{size}{unit}\"\n",
    "\n",
    "    @property\n",
    "    def readable_file_size(self):\n",
    "        return self.make_readable(self.file_size)\n",
    "\n",
    "    @property\n",
    "    def bytes_per_second(self):\n",
    "        return self.complete_size / self.elapsed\n",
    "\n",
    "    @property\n",
    "    def readable_bytes_per_second(self):\n",
    "        return self.make_readable(self.bytes_per_second)\n",
    "\n",
    "    def dict_with_properties(self):\n",
    "        return {\n",
    "            **super().dict(),\n",
    "            \"file_size_h\": self.readable_file_size,\n",
    "            \"bytes_per_second\": self.bytes_per_second,\n",
    "            \"bytes_per_second_h\": self.readable_bytes_per_second,\n",
    "        }\n",
    "\n",
    "\n",
    "# This does not work yet\n",
    "#     def dict(self):\n",
    "#         _dict = super().dict()\n",
    "#         return {\n",
    "#             **super().dict(),\n",
    "#             \"file_size_h\": self.readable_file_size,\n",
    "#             \"bytes_per_second\": self.bytes_per_second,\n",
    "#             \"bytes_per_second_h\": self.readable_bytes_per_second,\n",
    "#         }\n",
    "\n",
    "#     def json(self):\n",
    "#         return json.dumps(self.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-religion",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server': 'nginx', 'client': 'httpx', 'file_size': 1000000, 'elapsed': 3.0, 'complete_size': 100000000}\n",
      "{'server': 'nginx', 'client': 'httpx', 'file_size': 1000000, 'elapsed': 3.0, 'complete_size': 100000000, 'file_size_h': '976.56KB', 'bytes_per_second': 33333333.333333332, 'bytes_per_second_h': '31.79MB'}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"file_size = 10 ** 6\\ncomplete_size = 100 * file_size\\nresult = BenchmarkResult(\\n    server=\\\"nginx\\\",\\n    client=\\\"httpx\\\",\\n    file_size=file_size,\\n    elapsed=3.0,\\n    complete_size=complete_size,\\n)\\nprint(result.dict())\\nprint(result.dict_with_properties())\";\n",
       "                var nbb_formatted_code = \"file_size = 10 ** 6\\ncomplete_size = 100 * file_size\\nresult = BenchmarkResult(\\n    server=\\\"nginx\\\",\\n    client=\\\"httpx\\\",\\n    file_size=file_size,\\n    elapsed=3.0,\\n    complete_size=complete_size,\\n)\\nprint(result.dict())\\nprint(result.dict_with_properties())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_size = 10 ** 6\n",
    "complete_size = 100 * file_size\n",
    "result = BenchmarkResult(\n",
    "    server=\"nginx\",\n",
    "    client=\"httpx\",\n",
    "    file_size=file_size,\n",
    "    elapsed=3.0,\n",
    "    complete_size=complete_size,\n",
    ")\n",
    "print(result.dict())\n",
    "print(result.dict_with_properties())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-defendant",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"assert result.readable_bytes_per_second == \\\"31.79MB\\\"\\nassert \\\"file_size\\\" in result.json()\";\n",
       "                var nbb_formatted_code = \"assert result.readable_bytes_per_second == \\\"31.79MB\\\"\\nassert \\\"file_size\\\" in result.json()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert result.readable_bytes_per_second == \"31.79MB\"\n",
    "assert \"file_size\" in result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-light",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"class TestClient(BenchmarkClient):\\n    measured: bool = False\\n\\n    def measure(self, benchmark_row):\\n        self.measured = True\\n        print(\\\"measure_benchmark_row: \\\", benchmark_row)\\n        return 2.0\\n\\n\\nclass TestServer(BenchmarkServer):\\n    started: bool = False\\n    stopped: bool = False\\n\\n    def start(self):\\n        self.started = True\\n\\n    def stop(self):\\n        self.stopped = True\\n\\n\\nrow_params = {\\n    \\\"file_size\\\": 10 ** 6 * 10,\\n    \\\"duration\\\": 30,\\n    \\\"bandwidth\\\": 10 ** 9 / 8,\\n    \\\"file_creator\\\": DummyCreator(),\\n}\\nrow = BenchmarkRow(**row_params)\\n\\ntest_result = BenchmarkResult.build_empty_result(\\n    row, TestServer(name=\\\"server\\\"), TestClient(name=\\\"client\\\")\\n)\";\n",
       "                var nbb_formatted_code = \"class TestClient(BenchmarkClient):\\n    measured: bool = False\\n\\n    def measure(self, benchmark_row):\\n        self.measured = True\\n        print(\\\"measure_benchmark_row: \\\", benchmark_row)\\n        return 2.0\\n\\n\\nclass TestServer(BenchmarkServer):\\n    started: bool = False\\n    stopped: bool = False\\n\\n    def start(self):\\n        self.started = True\\n\\n    def stop(self):\\n        self.stopped = True\\n\\n\\nrow_params = {\\n    \\\"file_size\\\": 10 ** 6 * 10,\\n    \\\"duration\\\": 30,\\n    \\\"bandwidth\\\": 10 ** 9 / 8,\\n    \\\"file_creator\\\": DummyCreator(),\\n}\\nrow = BenchmarkRow(**row_params)\\n\\ntest_result = BenchmarkResult.build_empty_result(\\n    row, TestServer(name=\\\"server\\\"), TestClient(name=\\\"client\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TestClient(BenchmarkClient):\n",
    "    measured: bool = False\n",
    "\n",
    "    def measure(self, benchmark_row):\n",
    "        self.measured = True\n",
    "        print(\"measure_benchmark_row: \", benchmark_row)\n",
    "        return 2.0\n",
    "\n",
    "\n",
    "class TestServer(BenchmarkServer):\n",
    "    started: bool = False\n",
    "    stopped: bool = False\n",
    "\n",
    "    def start(self):\n",
    "        self.started = True\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "\n",
    "\n",
    "row_params = {\n",
    "    \"file_size\": 10 ** 6 * 10,\n",
    "    \"duration\": 30,\n",
    "    \"bandwidth\": 10 ** 9 / 8,\n",
    "    \"file_creator\": DummyCreator(),\n",
    "}\n",
    "row = BenchmarkRow(**row_params)\n",
    "\n",
    "test_result = BenchmarkResult.build_empty_result(\n",
    "    row, TestServer(name=\"server\"), TestClient(name=\"client\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-checkout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"assert test_result.server == \\\"server\\\"\\nassert test_result.client == \\\"client\\\"\";\n",
       "                var nbb_formatted_code = \"assert test_result.server == \\\"server\\\"\\nassert test_result.client == \\\"client\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert test_result.server == \"server\"\n",
    "assert test_result.client == \"client\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-universal",
   "metadata": {},
   "source": [
    "# Persistence / Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-lighting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# export\\n\\n\\nclass BaseRepository(BaseModel):\\n    session: Any = None\\n\\n    def get_result(self, benchmark, result):\\n        pass\\n\\n    def add_result(self, benchmark, result):\\n        pass\";\n",
       "                var nbb_formatted_code = \"# export\\n\\n\\nclass BaseRepository(BaseModel):\\n    session: Any = None\\n\\n    def get_result(self, benchmark, result):\\n        pass\\n\\n    def add_result(self, benchmark, result):\\n        pass\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class BaseRepository(BaseModel):\n",
    "    session: Any = None\n",
    "\n",
    "    def get_result(self, benchmark, result):\n",
    "        pass\n",
    "\n",
    "    def add_result(self, benchmark, result):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-chile",
   "metadata": {},
   "source": [
    "# Core Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-soccer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# export\\nimport cpuinfo\\nimport platform\\nimport subprocess\\n\\nfrom functools import cache\\n\\n\\ndef get_macos_machine_id():\\n    kwargs = {\\\"capture_output\\\": True, \\\"text\\\": True}\\n    output = subprocess.run(\\n        [\\n            \\\"/usr/sbin/system_profiler\\\",\\n            \\\"SPHardwareDataType\\\",\\n        ],\\n        **kwargs,\\n    )\\n    machine_id = None\\n    for line in output.stdout.split(\\\"\\\\n\\\"):\\n        if \\\"Serial Number\\\" in line:\\n            machine_id = line.split()[-1]\\n    return machine_id\\n\\n\\n@cache\\ndef get_machine_id():\\n    os = platform.platform().lower().split(\\\"-\\\")[0]\\n    os_lookup = {\\\"macos\\\": get_macos_machine_id}\\n    return os_lookup[os]()\\n\\n\\nclass Benchmark(BaseModel):\\n    duration: int = 30  # in seconds\\n    bandwidth: int = int(10 ** 9 / 8)  # in bytes per second\\n    file_sizes: list[int] = [10 ** 7, 10 ** 6, 10 ** 5]\\n    rows: list[BenchmarkRow] = []\\n    file_creator: Callable = FilesystemCreator()\\n    uname: Optional[Any] = platform.uname()\\n    cpuinfo: Optional[dict] = cpuinfo.get_cpu_info()\\n    servers: list[BenchmarkServer] = []\\n    clients: list[BenchmarkClient] = []\\n    results: list[BenchmarkResult] = []\\n    repository: Optional[BaseRepository] = None\\n    machine_id: str = get_machine_id()\\n\\n    @property\\n    def uname_json(self):\\n        return json.dumps(self.uname)\\n\\n    def __hash__(self):\\n        return hash(self.machine_id)\\n\\n    def __eq__(self, other):\\n        self.machine_id == other.machine_id\\n\\n    def create_row_from_file_size(self, file_size):\\n        do_not_copy = {\\n            \\\"rows\\\",\\n            \\\"file_sizes\\\",\\n            \\\"servers\\\",\\n            \\\"clients\\\",\\n            \\\"results\\\",\\n            \\\"repository\\\",\\n        }\\n        kwargs = {k: v for k, v in dict(self).items() if k not in do_not_copy}\\n        br = BenchmarkRow(file_size=file_size, **kwargs)\\n        br.create_files()\\n        return br\\n\\n    def create_rows(self):\\n        if len(self.rows) > 0:\\n            # benchmark rows were already created\\n            return\\n\\n        # create a row for each file_size\\n        for file_size in self.file_sizes:\\n            self.rows.append(self.create_row_from_file_size(file_size))\\n\\n    def build_empty_result(self, row, server, client):\\n        return BenchmarkResult(\\n            server=server.name,\\n            client=client.name,\\n            file_size=row.file_size,\\n            elapsed=elapsed,\\n            complete_size=row.complete_size,\\n            platform=self.uname.machine,\\n        )\\n\\n    def test_server_with_client(self, server, client):\\n        for row in self.rows:\\n            result = BenchmarkResult.build_empty_result(row, server, client)\\n            if (\\n                self.repository is not None\\n                and (\\n                    already_measured := self.repository.get_result(self, result)\\n                ).elapsed\\n                is not None\\n            ):\\n                print(\\\"already measured: \\\", already_measured)\\n                result = already_measured\\n            else:\\n                if not server.started:\\n                    server.start()\\n                result.elapsed = client.measure(row)\\n                if self.repository is not None:\\n                    self.repository.add_result(self, result)\\n                print(\\\"measured: \\\", result)\\n            self.results.append(result)\\n\\n    def run(self):\\n        for server in self.servers:\\n            # start with servers, because they are more expensive to create\\n            print(f\\\"server: {server}\\\")\\n            for client in self.clients:\\n                self.test_server_with_client(server, client)\\n            if server.started:\\n                server.stop()\\n\\n    def json(self):\\n        # return super().json(exclude={\\\"rows\\\", \\\"repository\\\"})\\n        fields = {\\n            \\\"duration\\\",\\n            \\\"bandwidth\\\",\\n            \\\"cpuinfo\\\",\\n        }\\n        return super().json(include=fields)\\n\\n    @property\\n    def results_frame(self):\\n        return pd.DataFrame([r.dict_with_properties() for r in self.results])\";\n",
       "                var nbb_formatted_code = \"# export\\nimport cpuinfo\\nimport platform\\nimport subprocess\\n\\nfrom functools import cache\\n\\n\\ndef get_macos_machine_id():\\n    kwargs = {\\\"capture_output\\\": True, \\\"text\\\": True}\\n    output = subprocess.run(\\n        [\\n            \\\"/usr/sbin/system_profiler\\\",\\n            \\\"SPHardwareDataType\\\",\\n        ],\\n        **kwargs,\\n    )\\n    machine_id = None\\n    for line in output.stdout.split(\\\"\\\\n\\\"):\\n        if \\\"Serial Number\\\" in line:\\n            machine_id = line.split()[-1]\\n    return machine_id\\n\\n\\n@cache\\ndef get_machine_id():\\n    os = platform.platform().lower().split(\\\"-\\\")[0]\\n    os_lookup = {\\\"macos\\\": get_macos_machine_id}\\n    return os_lookup[os]()\\n\\n\\nclass Benchmark(BaseModel):\\n    duration: int = 30  # in seconds\\n    bandwidth: int = int(10 ** 9 / 8)  # in bytes per second\\n    file_sizes: list[int] = [10 ** 7, 10 ** 6, 10 ** 5]\\n    rows: list[BenchmarkRow] = []\\n    file_creator: Callable = FilesystemCreator()\\n    uname: Optional[Any] = platform.uname()\\n    cpuinfo: Optional[dict] = cpuinfo.get_cpu_info()\\n    servers: list[BenchmarkServer] = []\\n    clients: list[BenchmarkClient] = []\\n    results: list[BenchmarkResult] = []\\n    repository: Optional[BaseRepository] = None\\n    machine_id: str = get_machine_id()\\n\\n    @property\\n    def uname_json(self):\\n        return json.dumps(self.uname)\\n\\n    def __hash__(self):\\n        return hash(self.machine_id)\\n\\n    def __eq__(self, other):\\n        self.machine_id == other.machine_id\\n\\n    def create_row_from_file_size(self, file_size):\\n        do_not_copy = {\\n            \\\"rows\\\",\\n            \\\"file_sizes\\\",\\n            \\\"servers\\\",\\n            \\\"clients\\\",\\n            \\\"results\\\",\\n            \\\"repository\\\",\\n        }\\n        kwargs = {k: v for k, v in dict(self).items() if k not in do_not_copy}\\n        br = BenchmarkRow(file_size=file_size, **kwargs)\\n        br.create_files()\\n        return br\\n\\n    def create_rows(self):\\n        if len(self.rows) > 0:\\n            # benchmark rows were already created\\n            return\\n\\n        # create a row for each file_size\\n        for file_size in self.file_sizes:\\n            self.rows.append(self.create_row_from_file_size(file_size))\\n\\n    def build_empty_result(self, row, server, client):\\n        return BenchmarkResult(\\n            server=server.name,\\n            client=client.name,\\n            file_size=row.file_size,\\n            elapsed=elapsed,\\n            complete_size=row.complete_size,\\n            platform=self.uname.machine,\\n        )\\n\\n    def test_server_with_client(self, server, client):\\n        for row in self.rows:\\n            result = BenchmarkResult.build_empty_result(row, server, client)\\n            if (\\n                self.repository is not None\\n                and (\\n                    already_measured := self.repository.get_result(self, result)\\n                ).elapsed\\n                is not None\\n            ):\\n                print(\\\"already measured: \\\", already_measured)\\n                result = already_measured\\n            else:\\n                if not server.started:\\n                    server.start()\\n                result.elapsed = client.measure(row)\\n                if self.repository is not None:\\n                    self.repository.add_result(self, result)\\n                print(\\\"measured: \\\", result)\\n            self.results.append(result)\\n\\n    def run(self):\\n        for server in self.servers:\\n            # start with servers, because they are more expensive to create\\n            print(f\\\"server: {server}\\\")\\n            for client in self.clients:\\n                self.test_server_with_client(server, client)\\n            if server.started:\\n                server.stop()\\n\\n    def json(self):\\n        # return super().json(exclude={\\\"rows\\\", \\\"repository\\\"})\\n        fields = {\\n            \\\"duration\\\",\\n            \\\"bandwidth\\\",\\n            \\\"cpuinfo\\\",\\n        }\\n        return super().json(include=fields)\\n\\n    @property\\n    def results_frame(self):\\n        return pd.DataFrame([r.dict_with_properties() for r in self.results])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import cpuinfo\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "from functools import cache\n",
    "\n",
    "\n",
    "def get_macos_machine_id():\n",
    "    kwargs = {\"capture_output\": True, \"text\": True}\n",
    "    output = subprocess.run(\n",
    "        [\n",
    "            \"/usr/sbin/system_profiler\",\n",
    "            \"SPHardwareDataType\",\n",
    "        ],\n",
    "        **kwargs,\n",
    "    )\n",
    "    machine_id = None\n",
    "    for line in output.stdout.split(\"\\n\"):\n",
    "        if \"Serial Number\" in line:\n",
    "            machine_id = line.split()[-1]\n",
    "    return machine_id\n",
    "\n",
    "\n",
    "@cache\n",
    "def get_machine_id():\n",
    "    os = platform.platform().lower().split(\"-\")[0]\n",
    "    os_lookup = {\"macos\": get_macos_machine_id}\n",
    "    return os_lookup[os]()\n",
    "\n",
    "\n",
    "class Benchmark(BaseModel):\n",
    "    duration: int = 30  # in seconds\n",
    "    bandwidth: int = int(10 ** 9 / 8)  # in bytes per second\n",
    "    file_sizes: list[int] = [10 ** 7, 10 ** 6, 10 ** 5]\n",
    "    rows: list[BenchmarkRow] = []\n",
    "    file_creator: Callable = FilesystemCreator()\n",
    "    uname: Optional[Any] = platform.uname()\n",
    "    cpuinfo: Optional[dict] = cpuinfo.get_cpu_info()\n",
    "    servers: list[BenchmarkServer] = []\n",
    "    clients: list[BenchmarkClient] = []\n",
    "    results: list[BenchmarkResult] = []\n",
    "    repository: Optional[BaseRepository] = None\n",
    "    machine_id: str = get_machine_id()\n",
    "\n",
    "    @property\n",
    "    def uname_json(self):\n",
    "        return json.dumps(self.uname)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.machine_id)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        self.machine_id == other.machine_id\n",
    "\n",
    "    def create_row_from_file_size(self, file_size):\n",
    "        do_not_copy = {\n",
    "            \"rows\",\n",
    "            \"file_sizes\",\n",
    "            \"servers\",\n",
    "            \"clients\",\n",
    "            \"results\",\n",
    "            \"repository\",\n",
    "        }\n",
    "        kwargs = {k: v for k, v in dict(self).items() if k not in do_not_copy}\n",
    "        br = BenchmarkRow(file_size=file_size, **kwargs)\n",
    "        br.create_files()\n",
    "        return br\n",
    "\n",
    "    def create_rows(self):\n",
    "        if len(self.rows) > 0:\n",
    "            # benchmark rows were already created\n",
    "            return\n",
    "\n",
    "        # create a row for each file_size\n",
    "        for file_size in self.file_sizes:\n",
    "            self.rows.append(self.create_row_from_file_size(file_size))\n",
    "\n",
    "    def build_empty_result(self, row, server, client):\n",
    "        return BenchmarkResult(\n",
    "            server=server.name,\n",
    "            client=client.name,\n",
    "            file_size=row.file_size,\n",
    "            elapsed=elapsed,\n",
    "            complete_size=row.complete_size,\n",
    "            platform=self.uname.machine,\n",
    "        )\n",
    "\n",
    "    def test_server_with_client(self, server, client):\n",
    "        for row in self.rows:\n",
    "            result = BenchmarkResult.build_empty_result(row, server, client)\n",
    "            if (\n",
    "                self.repository is not None\n",
    "                and (\n",
    "                    already_measured := self.repository.get_result(self, result)\n",
    "                ).elapsed\n",
    "                is not None\n",
    "            ):\n",
    "                print(\"already measured: \", already_measured)\n",
    "                result = already_measured\n",
    "            else:\n",
    "                if not server.started:\n",
    "                    server.start()\n",
    "                result.elapsed = client.measure(row)\n",
    "                if self.repository is not None:\n",
    "                    self.repository.add_result(self, result)\n",
    "                print(\"measured: \", result)\n",
    "            self.results.append(result)\n",
    "\n",
    "    def run(self):\n",
    "        for server in self.servers:\n",
    "            # start with servers, because they are more expensive to create\n",
    "            print(f\"server: {server}\")\n",
    "            for client in self.clients:\n",
    "                self.test_server_with_client(server, client)\n",
    "            if server.started:\n",
    "                server.stop()\n",
    "\n",
    "    def json(self):\n",
    "        # return super().json(exclude={\"rows\", \"repository\"})\n",
    "        fields = {\n",
    "            \"duration\",\n",
    "            \"bandwidth\",\n",
    "            \"cpuinfo\",\n",
    "        }\n",
    "        return super().json(include=fields)\n",
    "\n",
    "    @property\n",
    "    def results_frame(self):\n",
    "        return pd.DataFrame([r.dict_with_properties() for r in self.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# hide\\n\\nfrom collections import defaultdict\\n\\n\\nclass TestRepository(BaseRepository):\\n    results: dict = defaultdict(dict)\\n\\n    def get_result(self, benchmark, result):\\n        return self.results.get(benchmark, {}).get(result, result)\\n\\n    def add_result(self, benchmark, result):\\n        self.results[benchmark][result] = result\";\n",
       "                var nbb_formatted_code = \"# hide\\n\\nfrom collections import defaultdict\\n\\n\\nclass TestRepository(BaseRepository):\\n    results: dict = defaultdict(dict)\\n\\n    def get_result(self, benchmark, result):\\n        return self.results.get(benchmark, {}).get(result, result)\\n\\n    def add_result(self, benchmark, result):\\n        self.results[benchmark][result] = result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class TestRepository(BaseRepository):\n",
    "    results: dict = defaultdict(dict)\n",
    "\n",
    "    def get_result(self, benchmark, result):\n",
    "        return self.results.get(benchmark, {}).get(result, result)\n",
    "\n",
    "    def add_result(self, benchmark, result):\n",
    "        self.results[benchmark][result] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-capability",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "server: name='Nginx' started=False stopped=False\n",
      "measure_benchmark_row:  size: 10000000 duration: 2 bandwidth: 12500000\n",
      "measured:  server='Nginx' client='Httpx' file_size=10000000 elapsed=2.0 complete_size=25000000\n",
      "measure_benchmark_row:  size: 1000000 duration: 2 bandwidth: 12500000\n",
      "measured:  server='Nginx' client='Httpx' file_size=1000000 elapsed=2.0 complete_size=25000000\n",
      "measure_benchmark_row:  size: 100000 duration: 2 bandwidth: 12500000\n",
      "measured:  server='Nginx' client='Httpx' file_size=100000 elapsed=2.0 complete_size=25000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>server</th>\n",
       "      <th>client</th>\n",
       "      <th>file_size</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>complete_size</th>\n",
       "      <th>file_size_h</th>\n",
       "      <th>bytes_per_second</th>\n",
       "      <th>bytes_per_second_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nginx</td>\n",
       "      <td>Httpx</td>\n",
       "      <td>10000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25000000</td>\n",
       "      <td>9.54MB</td>\n",
       "      <td>12500000.0</td>\n",
       "      <td>11.92MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nginx</td>\n",
       "      <td>Httpx</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25000000</td>\n",
       "      <td>976.56KB</td>\n",
       "      <td>12500000.0</td>\n",
       "      <td>11.92MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nginx</td>\n",
       "      <td>Httpx</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25000000</td>\n",
       "      <td>97.66KB</td>\n",
       "      <td>12500000.0</td>\n",
       "      <td>11.92MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  server client  file_size  elapsed  complete_size file_size_h  \\\n",
       "0  Nginx  Httpx   10000000      2.0       25000000      9.54MB   \n",
       "1  Nginx  Httpx    1000000      2.0       25000000    976.56KB   \n",
       "2  Nginx  Httpx     100000      2.0       25000000     97.66KB   \n",
       "\n",
       "   bytes_per_second bytes_per_second_h  \n",
       "0        12500000.0            11.92MB  \n",
       "1        12500000.0            11.92MB  \n",
       "2        12500000.0            11.92MB  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# dont_test\\n\\nbyte = 8\\nhundred_mbit = 10 ** 8\\nbandwidth = hundred_mbit / byte\\nduration = 2  # seconds\\nfile_size = 10 ** 6 * 3  # 100MB\\nfile_sizes = [10 ** 7, 10 ** 6, 10 ** 5]\\n\\nbenchmark = Benchmark(\\n    duration=duration,\\n    bandwidth=bandwidth,\\n    file_creator=DummyCreator(),\\n    file_sizes=file_sizes,\\n    servers=[TestServer(name=\\\"Nginx\\\")],\\n    clients=[TestClient(name=\\\"Httpx\\\")],\\n    repository=TestRepository(),\\n)\\nbenchmark.create_rows()\\nprint(len(benchmark.rows))\\n\\nbenchmark.run()\\n# pprint(benchmark.results)\\nbenchmark.results_frame\";\n",
       "                var nbb_formatted_code = \"# dont_test\\n\\nbyte = 8\\nhundred_mbit = 10 ** 8\\nbandwidth = hundred_mbit / byte\\nduration = 2  # seconds\\nfile_size = 10 ** 6 * 3  # 100MB\\nfile_sizes = [10 ** 7, 10 ** 6, 10 ** 5]\\n\\nbenchmark = Benchmark(\\n    duration=duration,\\n    bandwidth=bandwidth,\\n    file_creator=DummyCreator(),\\n    file_sizes=file_sizes,\\n    servers=[TestServer(name=\\\"Nginx\\\")],\\n    clients=[TestClient(name=\\\"Httpx\\\")],\\n    repository=TestRepository(),\\n)\\nbenchmark.create_rows()\\nprint(len(benchmark.rows))\\n\\nbenchmark.run()\\n# pprint(benchmark.results)\\nbenchmark.results_frame\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dont_test\n",
    "\n",
    "byte = 8\n",
    "hundred_mbit = 10 ** 8\n",
    "bandwidth = hundred_mbit / byte\n",
    "duration = 2  # seconds\n",
    "file_size = 10 ** 6 * 3  # 100MB\n",
    "file_sizes = [10 ** 7, 10 ** 6, 10 ** 5]\n",
    "\n",
    "benchmark = Benchmark(\n",
    "    duration=duration,\n",
    "    bandwidth=bandwidth,\n",
    "    file_creator=DummyCreator(),\n",
    "    file_sizes=file_sizes,\n",
    "    servers=[TestServer(name=\"Nginx\")],\n",
    "    clients=[TestClient(name=\"Httpx\")],\n",
    "    repository=TestRepository(),\n",
    ")\n",
    "benchmark.create_rows()\n",
    "print(len(benchmark.rows))\n",
    "\n",
    "benchmark.run()\n",
    "# pprint(benchmark.results)\n",
    "benchmark.results_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-youth",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 ms, sys: 734 s, total: 18.5 ms\n",
      "Wall time: 18.9 ms\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"%%time\\nfrom collections import namedtuple\\n\\nTestPlatform = namedtuple(\\\"TestPlatform\\\", [\\\"machine\\\"])\\n    \\nbyte = 8\\ngigabit = 10 ** 9\\nfile_sizes = [10 ** 7, 10 ** 6, 10 ** 5]\\n\\ntest_params = {\\n    \\\"duration\\\": 3,\\n    \\\"bandwidth\\\": gigabit / byte / 10,  # divided by ten for test duration\\n    \\\"file_creator\\\": DummyCreator(),\\n    \\\"file_sizes\\\": file_sizes,\\n    \\\"cpuinfo\\\": {\\\"python_version\\\": 4.0},\\n    \\\"uname\\\": TestPlatform(\\\"M3\\\"),\\n    \\\"repository\\\": TestRepository(),\\n}\\n\\ntest_benchmark = Benchmark(**test_params)\\n\\ntest_benchmark.create_rows()\\nassert len(test_benchmark.rows) == len(file_sizes)\";\n",
       "                var nbb_formatted_code = \"%%time\\nfrom collections import namedtuple\\n\\nTestPlatform = namedtuple(\\\"TestPlatform\\\", [\\\"machine\\\"])\\n    \\nbyte = 8\\ngigabit = 10 ** 9\\nfile_sizes = [10 ** 7, 10 ** 6, 10 ** 5]\\n\\ntest_params = {\\n    \\\"duration\\\": 3,\\n    \\\"bandwidth\\\": gigabit / byte / 10,  # divided by ten for test duration\\n    \\\"file_creator\\\": DummyCreator(),\\n    \\\"file_sizes\\\": file_sizes,\\n    \\\"cpuinfo\\\": {\\\"python_version\\\": 4.0},\\n    \\\"uname\\\": TestPlatform(\\\"M3\\\"),\\n    \\\"repository\\\": TestRepository(),\\n}\\n\\ntest_benchmark = Benchmark(**test_params)\\n\\ntest_benchmark.create_rows()\\nassert len(test_benchmark.rows) == len(file_sizes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from collections import namedtuple\n",
    "\n",
    "TestPlatform = namedtuple(\"TestPlatform\", [\"machine\"])\n",
    "    \n",
    "byte = 8\n",
    "gigabit = 10 ** 9\n",
    "file_sizes = [10 ** 7, 10 ** 6, 10 ** 5]\n",
    "\n",
    "test_params = {\n",
    "    \"duration\": 3,\n",
    "    \"bandwidth\": gigabit / byte / 10,  # divided by ten for test duration\n",
    "    \"file_creator\": DummyCreator(),\n",
    "    \"file_sizes\": file_sizes,\n",
    "    \"cpuinfo\": {\"python_version\": 4.0},\n",
    "    \"uname\": TestPlatform(\"M3\"),\n",
    "    \"repository\": TestRepository(),\n",
    "}\n",
    "\n",
    "test_benchmark = Benchmark(**test_params)\n",
    "\n",
    "test_benchmark.create_rows()\n",
    "assert len(test_benchmark.rows) == len(file_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server: name='bar' started=False stopped=False\n",
      "measure_benchmark_row:  size: 10000000 duration: 3 bandwidth: 12500000\n",
      "measured:  server='bar' client='foo' file_size=10000000 elapsed=2.0 complete_size=37500000\n",
      "measure_benchmark_row:  size: 1000000 duration: 3 bandwidth: 12500000\n",
      "measured:  server='bar' client='foo' file_size=1000000 elapsed=2.0 complete_size=37500000\n",
      "measure_benchmark_row:  size: 100000 duration: 3 bandwidth: 12500000\n",
      "measured:  server='bar' client='foo' file_size=100000 elapsed=2.0 complete_size=37500000\n",
      "CPU times: user 16.4 ms, sys: 1.62 ms, total: 18 ms\n",
      "Wall time: 16.8 ms\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\nclass TestClient(BenchmarkClient):\\n    measured: bool = False\\n\\n    def measure(self, benchmark_row):\\n        self.measured = True\\n        print(\\\"measure_benchmark_row: \\\", benchmark_row)\\n        return 2.0\\n\\n\\nclass TestServer(BenchmarkServer):\\n    started: bool = False\\n    stopped: bool = False\\n\\n    def start(self):\\n        self.started = True\\n\\n    def stop(self):\\n        self.stopped = True\\n\\n\\ntest_params = {\\n    **test_params,\\n    \\\"clients\\\": [TestClient(name=\\\"foo\\\")],\\n    \\\"servers\\\": [TestServer(name=\\\"bar\\\")],\\n}\\ntest_benchmark = Benchmark(**test_params)\\ntest_benchmark.create_rows()\\ntest_benchmark.run()\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\nclass TestClient(BenchmarkClient):\\n    measured: bool = False\\n\\n    def measure(self, benchmark_row):\\n        self.measured = True\\n        print(\\\"measure_benchmark_row: \\\", benchmark_row)\\n        return 2.0\\n\\n\\nclass TestServer(BenchmarkServer):\\n    started: bool = False\\n    stopped: bool = False\\n\\n    def start(self):\\n        self.started = True\\n\\n    def stop(self):\\n        self.stopped = True\\n\\n\\ntest_params = {\\n    **test_params,\\n    \\\"clients\\\": [TestClient(name=\\\"foo\\\")],\\n    \\\"servers\\\": [TestServer(name=\\\"bar\\\")],\\n}\\ntest_benchmark = Benchmark(**test_params)\\ntest_benchmark.create_rows()\\ntest_benchmark.run()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class TestClient(BenchmarkClient):\n",
    "    measured: bool = False\n",
    "\n",
    "    def measure(self, benchmark_row):\n",
    "        self.measured = True\n",
    "        print(\"measure_benchmark_row: \", benchmark_row)\n",
    "        return 2.0\n",
    "\n",
    "\n",
    "class TestServer(BenchmarkServer):\n",
    "    started: bool = False\n",
    "    stopped: bool = False\n",
    "\n",
    "    def start(self):\n",
    "        self.started = True\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "\n",
    "\n",
    "test_params = {\n",
    "    **test_params,\n",
    "    \"clients\": [TestClient(name=\"foo\")],\n",
    "    \"servers\": [TestServer(name=\"bar\")],\n",
    "}\n",
    "test_benchmark = Benchmark(**test_params)\n",
    "test_benchmark.create_rows()\n",
    "test_benchmark.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-spank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"assert len(test_benchmark.results) == len(test_benchmark.rows)\";\n",
       "                var nbb_formatted_code = \"assert len(test_benchmark.results) == len(test_benchmark.rows)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert len(test_benchmark.results) == len(test_benchmark.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"assert test_benchmark.servers[0].started\\nassert test_benchmark.servers[0].stopped\";\n",
       "                var nbb_formatted_code = \"assert test_benchmark.servers[0].started\\nassert test_benchmark.servers[0].stopped\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert test_benchmark.servers[0].started\n",
    "assert test_benchmark.servers[0].stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-influence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"assert test_benchmark.uname.machine == \\\"M3\\\"\\nassert \\\"python_version\\\" in test_benchmark.cpuinfo\";\n",
       "                var nbb_formatted_code = \"assert test_benchmark.uname.machine == \\\"M3\\\"\\nassert \\\"python_version\\\" in test_benchmark.cpuinfo\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert test_benchmark.uname.machine == \"M3\"\n",
    "assert \"python_version\" in test_benchmark.cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-variety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"assert \\\"duration\\\" in test_benchmark.json()\";\n",
       "                var nbb_formatted_code = \"assert \\\"duration\\\" in test_benchmark.json()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert \"duration\" in test_benchmark.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-gothic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"assert len(test_benchmark.repository.results[test_benchmark]) == len(\\n    test_benchmark.results\\n)\";\n",
       "                var nbb_formatted_code = \"assert len(test_benchmark.repository.results[test_benchmark]) == len(\\n    test_benchmark.results\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert len(test_benchmark.repository.results[test_benchmark]) == len(\n",
    "    test_benchmark.results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-coach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server: name='bar' started=True stopped=True\n",
      "already measured:  server='bar' client='foo' file_size=10000000 elapsed=2.0 complete_size=37500000\n",
      "already measured:  server='bar' client='foo' file_size=1000000 elapsed=2.0 complete_size=37500000\n",
      "already measured:  server='bar' client='foo' file_size=100000 elapsed=2.0 complete_size=37500000\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# assert already measured results are not measured again\\ntest_benchmark.clients = [TestClient(name=\\\"foo\\\")]\\ntest_benchmark.run()\\nassert test_benchmark.clients[0].measured == False\";\n",
       "                var nbb_formatted_code = \"# assert already measured results are not measured again\\ntest_benchmark.clients = [TestClient(name=\\\"foo\\\")]\\ntest_benchmark.run()\\nassert test_benchmark.clients[0].measured == False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assert already measured results are not measured again\n",
    "test_benchmark.clients = [TestClient(name=\"foo\")]\n",
    "test_benchmark.run()\n",
    "assert test_benchmark.clients[0].measured == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-tampa",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_django_views.ipynb.\n",
      "Converted 01_fastapi_views.ipynb.\n",
      "Converted 02_docker_servers.ipynb.\n",
      "Converted 02_local_servers.ipynb.\n",
      "Converted 03_benchmark_clients.ipynb.\n",
      "Converted 04_persistence.ipynb.\n",
      "Converted 05_run_benchmark.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# dont_test\\n\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n",
       "                var nbb_formatted_code = \"# dont_test\\n\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dont_test\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-climb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
