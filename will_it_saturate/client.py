# AUTOGENERATED! DO NOT EDIT! File to edit: 03_benchmark_clients.ipynb (unless otherwise specified).

__all__ = ['HttpxClient', 'run_httpx', 'counter', 'request', 'AioHttpResponse', 'AioHttpClient', 'WrkClient', 'counter',
           'request']

# Cell

import os
import math
import time
import httpx
import asyncio
import aiohttp
import subprocess

from pathlib import Path
from multiprocessing import Pool
from multiprocessing import set_start_method

from .core import Benchmark, BaseServer, BaseClient

# Cell


# just here because of broken nbdev confusing lua with python
counter = 0
request = None


class HttpxClient(BaseClient):
    async def measure_server(self, benchmark_row):
        print("measure server")
        urls = [bf.url for bf in benchmark_row.files]
        print(urls[0])
        max_connections = min(benchmark_row.number_of_connections, 100)
        limits = httpx.Limits(
            max_keepalive_connections=5, max_connections=max_connections
        )
        timeout = httpx.Timeout(30.0, connect=60.0)
        start = time.perf_counter()
        async with httpx.AsyncClient(limits=limits, timeout=timeout) as client:
            responses = await asyncio.gather(*[client.get(url) for url in urls])
        elapsed = time.perf_counter() - start
        print("done: ", elapsed)
        print("responses status: ", responses[0].status_code)
        return elapsed, responses

    def measure_in_new_process(self, benchmark_row):
        print("new process")
        elapsed, responses = asyncio.run(self.measure_server(benchmark_row))
        self.verify_checksums(benchmark_row.files, responses)
        return elapsed

    def measure(self, benchmark_row):
        print("measure")
        with Pool(1) as p:
            [result] = p.map(self.measure_in_new_process, [benchmark_row])
        return result


def run_httpx():
    byte = 8
    gigabit = 10 ** 9
    bandwidth = gigabit / byte

    # file_sizes = [10 ** 7, 10 ** 6]
    # file_sizes = [10 ** 7, 10 ** 6, 10 ** 5]
    file_sizes = [10 ** 7]

    benchmark = Benchmark(
        bandwidth=bandwidth,
        duration=3,
        file_sizes=file_sizes,
        servers=[BenchmarkServer(name="uvicorn")],
        clients=[HttpxClient(name="httpx")],
    )
    benchmark.create_rows()
    benchmark.run()
    print(benchmark.results_frame)

# Cell


class AioHttpResponse:
    def __init__(self, url, content):
        self.url = url
        self.content = content


class AioHttpClient(BaseClient):
    async def fetch_page(self, session, url):
        async with session.get(url) as response:
            content = await response.read()
            return AioHttpResponse(url, content)

    async def measure_server(self, benchmark_row):
        urls = [bf.url for bf in benchmark_row.files]
        max_connections = min(benchmark_row.number_of_connections, 200)
        conn = aiohttp.TCPConnector(limit=max_connections)
        responses = []
        start = time.perf_counter()
        async with aiohttp.ClientSession(connector=conn) as session:
            tasks = [asyncio.create_task(self.fetch_page(session, url)) for url in urls]
            responses = await asyncio.gather(*tasks)
        elapsed = time.perf_counter() - start
        return elapsed, responses

    def measure_in_new_process(self, benchmark_row):
        elapsed, responses = asyncio.run(self.measure_server(benchmark_row))
        self.verify_checksums(benchmark_row.files, responses)
        return elapsed

    def measure(self, benchmark_row):
        with Pool(1) as p:
            [result] = p.map(self.measure_in_new_process, [benchmark_row])
        return result

# Cell


class WrkClient(BaseClient):
    connections: int = 200
    duration: int = 20
    threads: int = 1

    def create_urls_string(self, benchmark_row):
        urls = []
        for bf in benchmark_row.files:
            urls.append(f'    {{path = "/{bf.path}"}},')
        return "\n".join(urls)

    def create_lua_script(self, benchmark_row):
        requests_head = "requests = {"
        requests_tail = "}"
        lua_body = """
print(requests[1])

if #requests <= 0 then
  print("multiplerequests: No requests found.")
  os.exit()
end

print("multiplerequests: Found " .. #requests .. " requests")

counter = 1
request = function()
  -- Get the next requests array element
  local request_object = requests[counter]

  -- Increment the counter
  counter = counter + 1

  -- If the counter is longer than the requests array length -> stop and exit
  if counter > #requests then
    wrk.thread:stop()
    os.exit()
  end

  -- Return the request object with the current URL path
  return wrk.format(request_object.method, request_object.path, request_object.headers, request_object.body)
end
        """
        urls = self.create_urls_string(benchmark_row)
        lua = "\n".join([requests_head, urls, requests_tail, lua_body])
        with Path(f"wrk.lua").open("w") as f:
            f.write(lua)

    def run_wrk(self):
        kwargs = {"capture_output": True, "text": True}
        start = time.perf_counter()
        output = subprocess.run(
            [
                "wrk",
                "-c",
                str(self.connections),
                "-t",
                str(self.threads),
                "-s",
                "wrk.lua",
                "http://localhost:8000",
            ],
            **kwargs,
        )
        elapsed = time.perf_counter() - start
        return elapsed

    def measure(self, benchmark_row):
        self.create_lua_script(benchmark_row)
        elapsed = self.run_wrk()
        return elapsed